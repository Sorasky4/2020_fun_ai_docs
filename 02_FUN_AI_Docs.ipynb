{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUN AI 第2回 深層学習とPyTorch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 深層学習とは\n",
    "\n",
    "第0回でも触れたが、深層学習の定義として、\n",
    "\n",
    "機械学習のうち\n",
    "\n",
    "- 複雑なネットワークを用いる\n",
    "\n",
    "- 人間が特徴量抽出を行わない\n",
    "\n",
    "ものと覚えておけばとりあえずいいだろう。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PyTorchとは\n",
    "Pythonによる深層学習向けのフレームワーク。\n",
    "\n",
    "公式より\n",
    ">PyTorch is an optimized tensor library for deep learning using GPUs and CPUs.\n",
    "\n",
    "PytTorchとは、GPU及びCPUを使用した、深層学習のために最適化されたテンソルライブラリである。\n",
    "\n",
    "資料でわからないことがあれば、https://pytorch.org/docs を調べれば大体は解決する"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 用語解説\n",
    "\n",
    "Python -> プログラミング言語の1つ。様々な分野のタスクを柔軟にこなせる。かつ、比較的書きやすいことから広く使われている。\n",
    "\n",
    "CPU -> Central Processing Unit の略。日本語にすると中央処理装置。PCには必ず搭載されており、キーボードやマウスなどから入力を受け取り、画面などへ出力を行う。コンピュータの制御・演算を行うことからコンピュータの頭脳と例えられることがある。\n",
    "\n",
    "GPU -> Graphics Processing Unit の略。元は描画処理特化のパーツだったが、近年GPGPU(General-purpose computing on GPU)という技術が発達し、その厖大な処理能力を、深層学習など他のタスクなどにも転用できるようになった。その結果、深層学習モデルの学習を今までよりも高速に行えるようになった。深層学習が流行した一端を担っている。\n",
    "\n",
    "テンソル -> ベクトルや行列の拡張表現。スカラを0階テンソル、ベクトルを1階テンソル。行列を2階テンソルとし、3階、4階…と次元が上がっていく。以下にサンプルコード示し、さらに解説する。\n",
    "\n",
    "ライブラリ -> プログラミング言語におけるライブラリとは、汎用性の高いプログラムをひとまとめにしたものをいう。ライブラリ単体では動作しないことが多い。ライブラリ(図書館)から便利なプログラム(本)を引き出して使うイメージ。\n",
    "\n",
    "フレームワーク -> プログラミングにおけるフレームワークとは、それ単体でアプリケーションなどを立ち上げることができるもののことを指す。PyTorchは深層学習フレームワークであり、ライブラリである。"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$$\n",
    "\\mathbf{a} \\,= (1, 2) \\\\\n",
    "\\mathbf{b} \\,= \\left(\n",
    "    \\begin{array}{c}\n",
    "    1 \\\\\n",
    "    2\n",
    "    \\end{array}\n",
    "    \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.Tensor([1, 2]) #行ベクトル\n",
    "b = torch.Tensor([[1], [2]]) #列ベクトル\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$$\n",
    "\\mathbf{c} = \\left(\n",
    "    \\begin{array}{cc}\n",
    "    2 & 0\\\\\n",
    "    0 & 1\n",
    "    \\end{array}\n",
    "    \\right)\n",
    "$$    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.Tensor([[2, 0], [0, 1]]) # 2x2の行列\n",
    "print(c)\n",
    "print(c.size()) # size() でテンソルの大きさを確認できる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.matmul(a,b) # aとbの内積"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "テンソルに対して、基本的な演算を行える\n",
    "\n",
    "まずは、cと同じく2x2の行列を宣言する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = torch.Tensor([[1, 2], [3, 1]])\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "テンソルは、和、差、積、スカラ倍、転置　などの計算を行える。詳しくは線形代数学Ⅰの履修内容になっているから、そちらにゆずる。\n",
    "\n",
    "スカラ倍はいわゆるn倍、転置は行列の行と列を入れ替える演算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'c+d:\\n{c+d}\\n')\n",
    "print(f'c-d:\\n{c-d}\\n')\n",
    "print(f'c*d:\\n{torch.matmul(c, d)}\\n')\n",
    "print(f'd*c:\\n{torch.matmul(d, c)}\\n')\n",
    "print(f'3*d:\\n{3*d}\\n')\n",
    "print(f'd^T:\\n{d.T}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.randn([100]) # 正規分布からランダムに取り出す\n",
    "print(z)\n",
    "print(z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "tensor([[[1., 1.],\n         [1., 1.]],\n\n        [[1., 1.],\n         [1., 1.]]])\n"
    }
   ],
   "source": [
    "# 3階以上のテンソルも宣言できる\n",
    "a = torch.ones([2, 2, 2])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "演習問題\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathbf{w} &= (1, 2, 3) \\\\\n",
    "\\mathbf{x} &= (x_1, x_2, x_3) \\\\\n",
    "\\mathbf{y} &= \\left(\n",
    "    \\begin{array}{ccc}\n",
    "    y_{11} & y_{12} & y_{13} \\\\\n",
    "    y_{21} & y_{22} & y_{23} \\\\\n",
    "    y_{31} & y_{32} & y_{33}\n",
    "    \\end{array}\n",
    "    \\right)\n",
    "\\end{align}\n",
    "$$\n",
    "について、以下を計算せよ\n",
    "\n",
    "(1) $\\mathbf{w} \\cdot \\mathbf{w}^T$ \n",
    "\n",
    "(2) $\\mathbf{w} \\cdot \\mathbf{x}^T$ \n",
    "\n",
    "(3) $\\mathbf{x} \\cdot \\mathbf{y}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python37364bitbaseconda429541fdaed24deaa7378a94fef3496a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}